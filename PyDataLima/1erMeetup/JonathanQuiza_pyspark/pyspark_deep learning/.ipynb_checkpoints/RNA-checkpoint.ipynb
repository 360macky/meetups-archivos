{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler,StringIndexer,VectorIndexer,IndexToString\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier,MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"RN\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def condition(r):\n",
    "    if (r == 1):\n",
    "        label = \"aprobado\"    \n",
    "    else:\n",
    "        label = \"no_aprobado\"\n",
    "    return label\n",
    "\n",
    "return_condition_udf = F.udf(lambda x: condition(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_columns_train(df):\n",
    "    df_train = df.select(F.col(\"v_0\").cast(\"String\"),\n",
    "                   F.col(\"v_1\").cast(\"Double\"),\n",
    "                   F.col(\"v_2\").cast(\"Double\"),\n",
    "                   F.col(\"v_3\").cast(\"Double\"),\n",
    "                   F.col(\"v_4\").cast(\"Double\"),\n",
    "                   F.col(\"v_5\").cast(\"Double\"),\n",
    "                   F.col(\"v_6\").cast(\"Double\"),\n",
    "                   F.col(\"v_7\").cast(\"Double\"),\n",
    "                   F.col(\"v_8\").cast(\"Double\"),\n",
    "                   F.col(\"v_9\").cast(\"Double\"), \n",
    "                   F.col(\"v_10\").cast(\"Double\"),\n",
    "                   F.col(\"v_11\").cast(\"Double\"),\n",
    "                   F.col(\"v_12\").cast(\"double\").alias(\"label\"))\n",
    "    df_train = df_train.withColumn(\"label\", return_condition_udf(F.col(\"label\")))\n",
    "    return df_train\n",
    "\n",
    "def get_df_columns_test(df):\n",
    "    df_test = df.select(F.col(\"v_0\").cast(\"String\"),\n",
    "                   F.col(\"v_1\").cast(\"Double\"),\n",
    "                   F.col(\"v_2\").cast(\"Double\"),\n",
    "                   F.col(\"v_3\").cast(\"Double\"),\n",
    "                   F.col(\"v_4\").cast(\"Double\"),\n",
    "                   F.col(\"v_5\").cast(\"Double\"),\n",
    "                   F.col(\"v_6\").cast(\"Double\"),\n",
    "                   F.col(\"v_7\").cast(\"Double\"),\n",
    "                   F.col(\"v_8\").cast(\"Double\"),\n",
    "                   F.col(\"v_9\").cast(\"Double\"), \n",
    "                   F.col(\"v_10\").cast(\"Double\"),\n",
    "                   F.col(\"v_11\").cast(\"Double\"))\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_train():\n",
    "    df = spark.read.format(\"com.databricks.spark.csv\")\\\n",
    "               .option(\"header\", \"true\")\\\n",
    "               .load(\"data/train.csv\") \n",
    "            \n",
    "    my_df = get_df_columns_train(df)\n",
    "    \n",
    "    my_df = get_df_columns_train(df)\n",
    "    feature_columns = my_df.columns[1:-1]\n",
    "    \n",
    "    #data preparations\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')   \n",
    "    dataset = assembler.transform(df)\n",
    "    \n",
    "    labelIndexer   = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(dataset)\n",
    "    featureIndexer  = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=2).fit(dataset)\n",
    "    \n",
    "    (trainingData, testData) = dataset.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    layers = [12, 5, 4, 4, 7]\n",
    "    \n",
    "    trainer = MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\\\n",
    "                                         maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "    labelConverter  = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                labels=labelIndexer.labels)\n",
    "\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, trainer, labelConverter])\n",
    "    model = pipeline.fit(trainingData)\n",
    "    predictions = model.transform(testData)\n",
    "    model.write().overwrite().save(\"data/model/RN\")\n",
    "    predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Predictions accuracy = %g, Test Error = %g\" % (accuracy,(1.0 - accuracy)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_test():\n",
    "    df = spark.read.format(\"com.databricks.spark.csv\")\\\n",
    "              .option(\"header\", \"true\")\\\n",
    "              .load(\"test.csv\") \n",
    "    df = get_df_columns_test(df)\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=df.columns[1:], outputCol='features')\n",
    "    pipeline = Pipeline(stages=[assembler])\n",
    "    pipelineModel = pipeline.fit(df)\n",
    "    \n",
    "    dataset = pipelineModel.transform(df)\n",
    "    \n",
    "     \n",
    "    loadedPipeline = PipelineModel.read().load(\"/jonathan/RN\")\n",
    "    predictions = loadedPipeline.transform(dataset)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(16,[0,3,7,8,9,12...|\n",
      "|       0.0|         0.0|(16,[0,3,7,8,9,12...|\n",
      "|       2.0|         2.0|(16,[2,5,7,8,11,1...|\n",
      "|       3.0|         3.0|(16,[2,5,6,12],[1...|\n",
      "|       0.0|         0.0|(16,[3,5,6,7,8,9,...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Predictions accuracy = 0.823529, Test Error = 0.176471\n"
     ]
    }
   ],
   "source": [
    "my_model = df_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_select = df2.select(\"animal_name\", \"predictedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_name</th>\n",
       "      <th>predictedLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>skimmer</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skua</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slowworm</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slug</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sole</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sparrow</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>squirrel</td>\n",
       "      <td>Mamal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>starfish</td>\n",
       "      <td>Invertebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stingray</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>swan</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>termite</td>\n",
       "      <td>Invertebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>toad</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tortoise</td>\n",
       "      <td>Invertebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tuatara</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tuna</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vampire</td>\n",
       "      <td>Mamal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vole</td>\n",
       "      <td>Mamal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vulture</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wallaby</td>\n",
       "      <td>Mamal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wasp</td>\n",
       "      <td>Invertebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wolf</td>\n",
       "      <td>Mamal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>worm</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wren</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal_name predictedLabel\n",
       "0      skimmer           Bird\n",
       "1         skua           Bird\n",
       "2     slowworm           Fish\n",
       "3         slug           Fish\n",
       "4         sole           Fish\n",
       "5      sparrow           Bird\n",
       "6     squirrel          Mamal\n",
       "7     starfish   Invertebrate\n",
       "8     stingray           Fish\n",
       "9         swan           Bird\n",
       "10     termite   Invertebrate\n",
       "11        toad           Bird\n",
       "12    tortoise   Invertebrate\n",
       "13     tuatara           Bird\n",
       "14        tuna           Fish\n",
       "15     vampire          Mamal\n",
       "16        vole          Mamal\n",
       "17     vulture           Bird\n",
       "18     wallaby          Mamal\n",
       "19        wasp   Invertebrate\n",
       "20        wolf          Mamal\n",
       "21        worm           Fish\n",
       "22        wren           Bird"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_select.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2 = PipelineModel.read().load(\"RN/mlp\")\n",
    "treeModel = model.stages[2]\n",
    "treeModel.layers\n",
    "treeModel.weights\n",
    "treeModel.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_spark]",
   "language": "python",
   "name": "conda-env-env_spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
