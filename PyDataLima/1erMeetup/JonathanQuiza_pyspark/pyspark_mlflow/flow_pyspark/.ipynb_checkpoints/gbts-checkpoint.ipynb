{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler,StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(predictions_and_labels):\n",
    "    \n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    auc_roc = model2.avgMetrics[0]\n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Accuracy = %s\" % float(auc_roc)*100)\n",
    "    print(\"Gini = %s\" % float(2 * auc_roc — 1)*100)\n",
    "    print(\"precision\", float(metrics.precision())*100)\n",
    "    print(\"recall\", float(metrics.recall())*100)\n",
    "\n",
    "    print('Confusion Matrix\\n', metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('APP').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_columns_train(df):\n",
    "    df_rows = df.select(\n",
    "        df.v_0.cast(\"String\"),\n",
    "        df.v_1.cast(\"Double\"),\n",
    "        df.v_2.cast(\"Double\"),\n",
    "        df.v_3.cast(\"Double\"),\n",
    "        df.v_4.cast(\"Double\"),\n",
    "        df.v_5.cast(\"Double\"),\n",
    "        df.v_6.cast(\"Double\"),\n",
    "        df.v_7.cast(\"Double\"),\n",
    "        df.v_8.cast(\"Double\"),\n",
    "        df.v_9.cast(\"Double\"),\n",
    "        df.v_10.cast(\"Double\"),\n",
    "        df.v_11.cast(\"Double\"),\n",
    "        df.v_12.cast(\"Integer\").alias(\"label\")\n",
    "    )\n",
    "    return df_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_columns_test(df):\n",
    "    df_rows = df.select(\n",
    "        df.v_0.cast(\"String\"),\n",
    "        df.v_1.cast(\"Double\"),\n",
    "        df.v_2.cast(\"Double\"),\n",
    "        df.v_3.cast(\"Double\"),\n",
    "        df.v_4.cast(\"Double\"),\n",
    "        df.v_5.cast(\"Double\"),\n",
    "        df.v_6.cast(\"Double\"),\n",
    "        df.v_7.cast(\"Double\"),\n",
    "        df.v_8.cast(\"Double\"),\n",
    "        df.v_9.cast(\"Double\"),\n",
    "        df.v_10.cast(\"Double\"),\n",
    "        df.v_11.cast(\"Double\"),\n",
    "        df.v_12.cast(\"Integer\").alias(\"label\")\n",
    "    )\n",
    "    return df_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_train():\n",
    "\n",
    "    df = spark.read.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .load(\"data/dataset.csv\")\n",
    "    \n",
    "    #data selections\n",
    "    my_df = get_df_columns_train(df)\n",
    "    feature_columns = my_df.columns[1:-1]\n",
    "    \n",
    "    #data preparations\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "    \n",
    "    pipeline = Pipeline(stages=[assembler])\n",
    "    pipelineModel = pipeline.fit(my_df)\n",
    "    pipelineModel.write().overwrite().save(\"data/model/Model_GBTS\")\n",
    "    \n",
    "    dataset = pipelineModel.transform(my_df)\n",
    "    \n",
    "    #data partitions\n",
    "    (trainingData, testData) = dataset.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    #gbts\n",
    "    iteration = 100\n",
    "    gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=iteration)\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "    \n",
    "    paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "\n",
    "    # Create 5-fold CrossValidator\n",
    "    cv = CrossValidator(estimator=gbt, \n",
    "                        estimatorParamMaps=paramGrid, \n",
    "                        evaluator=evaluator, \n",
    "                        numFolds=5)\n",
    "    \n",
    "    \n",
    "    #Train model using CV\n",
    "    model = cv.fit(trainingData).bestModel\n",
    "    model.write().overwrite().save(\"data/model/CVModel_LGR\")\n",
    "    \n",
    "    ## Predict and evaluate\n",
    "    predictions = model.transform(testData)\n",
    "    \n",
    "    \n",
    "    #BinaryClassificationEvaluator\n",
    "    evaluator2 = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "    \n",
    "    accuracy = evaluator2.evaluate(predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Test Error = %g\" % (1.0 — accuracy))\n",
    "\n",
    "\n",
    "    predictions_and_labels = predictions.select(\"prediction\", \"label\").rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "    print_metrics(predictions_and_labels)    \n",
    "    \n",
    "    return model      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_test(df):\n",
    "    my_df = get_df_columns_test(df)\n",
    "    feature_columns = my_df.columns[1:]\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "    pipeline = Pipeline(stages=[assembler])\n",
    "    \n",
    "    pipelineModel = pipeline.fit(my_df)\n",
    "    \n",
    "    dataset = pipelineModel.transform(my_df)\n",
    "    \n",
    "    loadedPipeline = PipelineModel.read().load(\"data/model/CVModel_GBTS\")\n",
    "    predictions = loadedPipeline.transform(dataset)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "Accuracy: 0.7480509395868928\n",
      "Summary Stats\n",
      "Accuracy = 0.6912599318955732\n",
      "Confusion Matrix\n",
      " DenseMatrix([[428.,  42.],\n",
      "             [230., 181.]])\n"
     ]
    }
   ],
   "source": [
    "# _train = False\n",
    "# _test = True\n",
    "_train = True\n",
    "_test = False\n",
    "\n",
    "if _train:\n",
    "    print(\"Training Model\")\n",
    "    my_model = df_train()\n",
    "elif _test:\n",
    "    print(\"Testing Model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_spark]",
   "language": "python",
   "name": "conda-env-env_spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
